WAVEFORMS: A Webtext Mixtape

An interactive scholarly webtext built for Kairos: A Journal of Rhetoric, Technology, and Pedagogy
This project is a working prototype of my forthcoming peer-reviewed publication. It integrates multimodal storytelling, research, and design through audio, transcripts, and interactive navigation. I coded the site from scratch in HTML, CSS, and JavaScript, using AI assistance to prototype quickly, troubleshoot bugs, and ensure accessibility.

🎯 Problem I Was Solving:
How can we present complex multimodal research in a way that is accessible, user-friendly, and engaging for diverse audiences? Academic PDFs fail to capture the richness of multimodal scholarship, so I set out to design a platform that lets users listen, read, and navigate dynamically.

⚙️ Technical Decisions:
Framework: Pure HTML, CSS, JavaScript (no heavy frameworks to keep it lightweight).
Accessibility: Implemented alt text, ARIA labels, keyboard navigation, and transcript toggles.
Audio Integration: Embedded SoundCloud players with synchronized transcript options.
Navigation: Custom collapsible menus and smooth scroll to guide users through multimodal sections.
AI Collaboration: Used Claude + GPT models to co-write/refactor JS functions and optimize CSS, speeding up iteration cycles.

🚀 Timeline:
Idea → working prototype: ~4 days
Iterative testing with accessibility checkers and peer reviewers.
Designed for future extensibility (additional tracks, interactive visuals, captioned video).

📂 What’s Inside:
/index.html → Main landing page with custom navigation
/styles/ → CSS for layout, typography, accessibility
/scripts/ → JS for collapsible menus, transcript toggles
/assets/ → Images, audio embeds, figcaptions, etc.

🌍 Live Demo:
https://bmoon2260.github.io/waveforms/

🔑 Key Takeaways:
Rapid prototyping of a complex multimodal artifact.
Integration of AI in the dev workflow for troubleshooting and iteration.
Bridging pedagogy and product design: turning abstract research into an interactive, accessible user experience.
